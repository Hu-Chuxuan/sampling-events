# sampling-events
This is a repo for exploring confidence interval for events generated from uniform random sampling using different sampling mechanism.

The following methods are implemented:
- Wald Test based on Central Limit Theorem.
- Markov Chain Monte Carlo (MCMC) using Metropolis-Hastings algorithm.
- Hoeffding.
- Bootstrap.
- Importance Sampling.
- Adaptive Importance Sampling.

Type
```bat
python test_all.py
```
to run an overall comparison of all implemented methods with default sample size 10000 and confidence interval 0.95.

Under this setting, ***Wald Test*** gives the closest estimation as well as the tightest confidence interval.

Or type
```bat
python test_all.py -c [confidence interval] -n [sample size]
```
for example,
```bat
python test_all.py -c 0.7 -n 1000
```

Test scripts for each of the algorithm are also provided.


To run Wald tests based on Central Limit Theorem, type

```bat
python clt.py
```

To run Hoeffding tests, type
```bat
python hoeffding.py
```

To run Bootstrap tests, type
```bat
python bootstrap.py
```

To run Markov Chain Monte Carlo (MCMC) tests based on Metropolis-Hastings algorithm, type
```bat
python mcmc.py
``` 

To run Importance Sampling and Adaptive Importance Sampling tests, type
```bat
python importance_sampling.py
```

For the starter task, two sampling techniques are implemented in the **algorithm.py** file: bootstrap and hoeffding inequality based approach. Events are generated in the **gen.py** file.

To run tests for these two algorithms, type

```bat
python test.py
```
in command prompt.

We can observe that:

1. As the user-defined error target and/or CI get larger, the average error rates of hoeffding based approach increases due to less samples.

2. As CI gets larger, the interval generated by bootstrap also increases.

Both align with theoretical analysis.
